# Automated ETL Process for Kaggle/Wikipedia Movie Data
The final code block can be found here: https://github.com/tylerah/movies-ETL/blob/main/ETL_create_database.ipynb
## Purpose
The purpose of this project was to write a code block that created an automated process for reading new data, transforming the new data into a cleaner/condensed form, and loading that data into an existing Postgres database. This code block was used specifically to take in three files containing movie information: a wikipedia json file, a kaggle metadata file, and MovieLens ratings data.

## Data Files
The Wikipedia json file can be found within the repository at this link: https://github.com/tylerah/movies-ETL/blob/main/resources/wikipedia-movies.json

Note that the MovieLens rating data was too large to upload to github. The Kaggle metadata and Movielens ratings data can be found here: https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset?resource=download
